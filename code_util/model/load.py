import torch
import torch

def load_partial_state_dict(model, state_dict_path, device='cpu', include=None, exclude=None):
    """
    ä» checkpoint åŠ è½½éƒ¨åˆ†å‚æ•°åˆ°æ¨¡å‹ä¸­ã€‚
    
    å‚æ•°:
        model (nn.Module): å½“å‰æ¨¡å‹ã€‚
        state_dict_path (str): checkpoint è·¯å¾„ã€‚
        device (str): åŠ è½½è®¾å¤‡ã€‚
        include (str or None): åªåŠ è½½åŒ…å«è¯¥å­—ç¬¦ä¸²çš„å‚æ•°ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰ã€‚
        exclude (str or None): ä¸åŠ è½½åŒ…å«è¯¥å­—ç¬¦ä¸²çš„å‚æ•°ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰ï¼Œä¼˜å…ˆçº§é«˜äº includeã€‚
    """
    print(f"ğŸ“‚ Loading checkpoint from: {state_dict_path}")
    state_dict = torch.load(state_dict_path, map_location=device)

    model_dict = model.state_dict()

    loaded_params = []
    missing_in_checkpoint = []
    missing_in_model = []

    def match_key(key):
        key_lower = key.lower()
        if exclude and exclude.lower() in key_lower:
            return False
        if include and include.lower() not in key_lower:
            return False
        return True

    filtered_dict = {}
    for k, v in state_dict.items():
        if not match_key(k):
            continue
        if k in model_dict:
            if v.shape == model_dict[k].shape:
                filtered_dict[k] = v
                loaded_params.append(k)
            else:
                print(f"[Shape mismatch] {k}: checkpoint {v.shape} != model {model_dict[k].shape}")
                missing_in_checkpoint.append(k)
        else:
            missing_in_model.append(k)

    model_dict.update(filtered_dict)
    model.load_state_dict(model_dict)

    # print("\nâœ… Loaded parameters:")
    # for k in loaded_params:
    #     print(f"  - {k}")

    print("\nâš ï¸ Not loaded (due to shape mismatch or not in checkpoint):")
    for k in model_dict.keys():
        if k not in filtered_dict:
            print(f"  - {k}")

    print("\nâ— Extra parameters in checkpoint not found in model:")
    for k in missing_in_model:
        print(f"  - {k}")


def set_trainable_params(model, trainable_keys=None, freeze_keys=None):
    """
    æ ¹æ®å…³é”®è¯è®¾ç½®æ¨¡å‹å‚æ•°æ˜¯å¦å¯è®­ç»ƒã€‚
    
    å‚æ•°ï¼š
        model (nn.Module): ç›®æ ‡æ¨¡å‹ã€‚
        trainable_keys (str or List[str] or None): å‚æ•°åä¸­åŒ…å«è¿™äº›å…³é”®è¯çš„è®¾ç½®ä¸ºå¯è®­ç»ƒï¼ˆrequires_grad=Trueï¼‰
        freeze_keys (str or List[str] or None): å‚æ•°åä¸­åŒ…å«è¿™äº›å…³é”®è¯çš„è®¾ç½®ä¸ºå†»ç»“ï¼ˆrequires_grad=Falseï¼‰ï¼Œä¼˜å…ˆçº§é«˜äº trainable_keysã€‚
    """
    def to_lower_list(x):
        if x is None:
            return []
        if isinstance(x, str):
            return [x.lower()]
        return [s.lower() for s in x]

    trainable_keys = to_lower_list(trainable_keys)
    freeze_keys = to_lower_list(freeze_keys)

    for name, param in model.named_parameters():
        name_lower = name.lower()

        if any(key in name_lower for key in freeze_keys):
            param.requires_grad = False
            print(f"ğŸ”’ Freezing: {name}")
        elif any(key in name_lower for key in trainable_keys):
            param.requires_grad = True
            print(f"âœ… Trainable: {name}")
        elif trainable_keys:
            # å¦‚æœæŒ‡å®šäº† trainable_keys ä½†å½“å‰å‚æ•°ä¸åŒ¹é…ä»»ä½•ä¸€ä¸ªï¼Œåˆ™é»˜è®¤å†»ç»“
            param.requires_grad = False
            print(f"âŒ Not trainable (filtered out): {name}")
        else:
            # å¦‚æœéƒ½æ²¡æŒ‡å®šï¼Œä¿æŒåŸçŠ¶
            pass

